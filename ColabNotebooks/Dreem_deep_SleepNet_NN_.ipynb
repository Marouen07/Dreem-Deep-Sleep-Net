{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Dreem deepSleepNet NN .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Marouen07/Dreem-Deep-Sleep-Net/blob/master/ColanNotebooks/Dreem_deepSleepNet_NN_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2nR2LVonwcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "upload=files.upload()\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!kaggle competitions download -c dreem-sleep-stages-2020 -p /content\n",
        "!unzip \\X_train.h5.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B7KjpNxYhogR",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PjiJO-LwW_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Create_dataset(measures,f):\n",
        "  \"\"\"getting data from h5py file\n",
        "    Parameters:\n",
        "    -------------\n",
        "    measures: List of sensors to take data from \n",
        "    f: H5py file containing the dataset ( memory efficient)\n",
        "\n",
        "    Output :\n",
        "    -------------\n",
        "    df : DataFrame containing the formatted data \n",
        "    y  : Dataframe of corrresponding Labels \n",
        "    \"\"\"\n",
        "\n",
        "  df=pd.concat([pd.DataFrame(f[i][:]) for i in measures],ignore_index=True)\n",
        "  y=pd.read_csv('y_train.csv')\n",
        "  y=y['sleep_stage'].values\n",
        "  #Standardizing Input\n",
        "  df=(df.sub(df.mean(axis=1),axis=0)).div(df.std(axis=1),axis=0)#(df.max(axis=1)-df.min(axis=1))\n",
        "  #reformatting the data so that we can feed it to our Neural Network Later on \n",
        "  n_measures=len(measures)\n",
        "  n_samples=df.shape[0]//n_measures\n",
        "  df['id']=df.index%n_samples\n",
        "  df['channel']=[measures[i] for i in df.index//n_samples]\n",
        "  df=df.set_index(['id','channel'])\n",
        "  df=df.sort_index()\n",
        "  return df,y,n_measures,n_samples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2EvzA6qZk8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_loader(X,y,batch_size,shuffle=True):\n",
        "  \"\"\"Creating DataLoaders to feed our NN with Data \n",
        "  \"\"\"\n",
        "  data=TensorDataset(torch.from_numpy(X).float(), torch.from_numpy(y))\n",
        "  loader = DataLoader(data, shuffle=shuffle, batch_size=batch_size)\n",
        "  return loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yxnzr5N0x1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Oversample(df,y,shape):\n",
        "  \"\"\"Oversampling Data to avoid Class inbalance issue \n",
        "  Parmaeters : \n",
        "  ------------\n",
        "  df: dataset \n",
        "  y: Labels\n",
        "  shape: for 1d Conv (n_samples,N_channels(=N_measures),Length(Sampling_Frequency*Duration))\n",
        "         for 2d Conv (n_samples,N_channels(=1),N_measures,Length(Sampling_Frequency*Duration))\n",
        "  Output: \n",
        "  -----------\n",
        "  oversampled splitted data (Train and Validation)\n",
        "  \"\"\"\n",
        "  X=df.values.reshape(shape[0],-1)\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.2)\n",
        "  X_resampled, y_resampled = SMOTE(n_jobs=-1).fit_resample(X_train, y_train)\n",
        " #Adapting Data Shape \n",
        "  X_resampled=X_resampled.reshape((X_resampled.shape[0],)+shape[1:])\n",
        "  X_val=X_val.reshape((X_val.shape[0],)+shape[1:])\n",
        "  return X_resampled,y_resampled,X_val,y_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EKsDszfuCEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Train_model(model,criterion,optimizer,loader,scheduler,mode='train'):\n",
        "  \"\"\"Model Training/Validation \n",
        "  ------------------------------\n",
        "  Output: \n",
        "  -----------\n",
        "  mean_loss: Mean loss over Epoch\"\"\"\n",
        "\n",
        "  if mode=='train':\n",
        "    model.train()\n",
        "  elif mode=='val': \n",
        "    model.eval()\n",
        "  else: \n",
        "    print('mode should be Train or Val')\n",
        "    return\n",
        "  losses=[]\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for inputs, labels in loader:\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    model.init_hidden(inputs.size(0))\n",
        "    optimizer.zero_grad()\n",
        "    with torch.set_grad_enabled(mode=='train'):\n",
        "      output = model(inputs)\n",
        "      loss = criterion(output, labels)\n",
        "      _,pred=torch.max(output, 1)\n",
        "      if mode=='train':\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    losses.append(loss.item())\n",
        "    correct+=float(torch.sum(pred==labels.data))\n",
        "    total+=float(inputs.shape[0])\n",
        "  if mode =='train':\n",
        "    scheduler.step()\n",
        "  mean_loss=np.mean(losses)\n",
        "  print('{} Loss {:.4f}  Acc : {:.2%}  '.format(mode,mean_loss,correct/total))\n",
        "  return mean_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osWPv7QDYOSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.optim import lr_scheduler\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, n_measures,fs, drop=.5,lstm=False):\n",
        "        super().__init__()\n",
        "        self.measures=n_measures\n",
        "        self.lstm_bool= lstm \n",
        "        self.n_layers=1\n",
        "        self.temporal = nn.Sequential(\n",
        "            nn.Conv1d(self.measures,128, fs//2,fs//10),nn.ReLU(inplace=True),nn.BatchNorm1d(128),nn.MaxPool1d(8,stride=8),nn.Dropout(drop),\n",
        "            nn.Conv1d(128,128, 8,stride=1),nn.ReLU(inplace=True),nn.BatchNorm1d(128),\n",
        "            nn.Conv1d(128,128, 8,stride=1),nn.ReLU(inplace=True),nn.BatchNorm1d(128),\n",
        "            nn.Conv1d(128,128, 8,stride=1),nn.ReLU(inplace=True),nn.BatchNorm1d(128),nn.MaxPool1d(4,stride=4),\n",
        "            nn.Dropout(drop))\n",
        "        \n",
        "        self.freq = nn.Sequential(\n",
        "            nn.Conv1d(self.measures,128, fs*4,stride=fs//3),nn.ReLU(inplace=True),nn.BatchNorm1d(128),nn.MaxPool1d(4,stride=4),nn.Dropout(drop),\n",
        "            nn.Conv1d(128,128, 6,stride=1),nn.ReLU(inplace=True),nn.BatchNorm1d(128),\n",
        "            nn.Conv1d(128,128, 6,stride=1),nn.ReLU(inplace=True),nn.BatchNorm1d(128),\n",
        "            nn.Conv1d(128,128, 6,stride=1),nn.ReLU(inplace=True),nn.BatchNorm1d(128),nn.MaxPool1d(2,stride=2),\n",
        "            nn.Dropout(drop))\n",
        "        \n",
        "        self.hidden_size=10*2\n",
        "        self.lstm=nn.LSTM(input_size=6,hidden_size=self.hidden_size,\n",
        "                    num_layers=self.n_layers,dropout=drop,batch_first=True,\n",
        "                    bidirectional =True)\n",
        "        self.post_lstm=nn.Sequential(nn.Linear(2560*2,5))\n",
        "        self.lin=nn.Sequential(nn.Linear(768,5))\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        # even with batch_first = True this remains same as docs\n",
        "        hidden_state = torch.zeros(self.n_layers*2,batch_size,self.hidden_size)\n",
        "        cell_state = torch.zeros(self.n_layers*2,batch_size,self.hidden_size)\n",
        "        self.hidden = (hidden_state.to(device), cell_state.to(device))\n",
        "    def forward(self, x):\n",
        "        x_t = self.temporal(x)\n",
        "        x_f=self.freq(x)\n",
        "        #print(x_t.shape,'  ',x_f.shape)\n",
        "        if self.lstm_bool:\n",
        "            x=torch.cat([x_f, x_t], dim=2)\n",
        "            \n",
        "            x,self.hidden=self.lstm(x,self.hidden)\n",
        "            x=x.contiguous().view(x.size(0), -1)\n",
        "            return self.post_lstm(x)\n",
        "        x_t=x_t.view(x_t.size(0), -1)\n",
        "        x_f=x_f.view(x_f.size(0), -1)\n",
        "        x=torch.cat([x_f, x_t], dim=1)\n",
        "        return self.lin(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD_TR2LYjkx9",
        "colab_type": "code",
        "outputId": "d8d0c782-5ed2-43a2-aece-e5340c78d255",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnhCwOMCTTD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f= h5py.File('X_train.h5', 'r')\n",
        "L=[i for i in f.keys()]\n",
        "df_eeg,y,n_measures,n_samples=Create_dataset(L[:1],f)\n",
        "F_s=50 #Sampling Frequency\n",
        "shape=(n_samples,n_measures,F_s*30)\n",
        "X_train,y_train,X_val,y_val=Oversample(df_eeg,y,shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfe0sx51dYse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=256\n",
        "train_loader=create_loader(X_train,y_train,batch_size)\n",
        "val_loader=create_loader(X_val,y_val,batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePWS8YPJNTEN",
        "colab_type": "code",
        "outputId": "96adb2a1-1180-47c5-baac-5a29491e633a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "classifier = Classifier(n_measures,F_s,lstm=False)\n",
        "classifier.to(device)\n",
        "optimizer = optim.Adam(classifier.parameters(),lr=0.1)#,weight_decay=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scheduler=lr_scheduler.StepLR(optimizer,step_size=5,gamma=0.1)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gss0CzMJlNfV",
        "colab_type": "code",
        "outputId": "1224d0b2-a110-442d-cbb0-1c59541b9fbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "epochs=10\n",
        "Losses_v=[]\n",
        "Losses_t=[]\n",
        "for epoch in range(epochs):\n",
        "  print('epoch: ',epoch)\n",
        "  Losses_t+=Train_model(classifier,criterion,optimizer,train_loader,scheduler,mode='train')\n",
        "  Losses_v+=Train_model(classifier,criterion,optimizer,val_loader,scheduler,mode='val')"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:  0\n",
            "train Loss 0.9344  Acc : 62.79%  \n",
            "val Loss 1.0551  Acc : 59.01%  \n",
            "epoch:  1\n",
            "train Loss 0.9293  Acc : 63.06%  \n",
            "val Loss 1.0547  Acc : 59.15%  \n",
            "epoch:  2\n",
            "train Loss 0.9311  Acc : 62.96%  \n",
            "val Loss 1.0556  Acc : 59.28%  \n",
            "epoch:  3\n",
            "train Loss 0.9313  Acc : 63.06%  \n",
            "val Loss 1.0540  Acc : 59.23%  \n",
            "epoch:  4\n",
            "train Loss 0.9318  Acc : 63.14%  \n",
            "val Loss 1.0608  Acc : 59.09%  \n",
            "epoch:  5\n",
            "train Loss 0.9305  Acc : 62.85%  \n",
            "val Loss 1.0506  Acc : 59.25%  \n",
            "epoch:  6\n",
            "train Loss 0.9338  Acc : 62.87%  \n",
            "val Loss 1.0591  Acc : 59.30%  \n",
            "epoch:  7\n",
            "train Loss 0.9294  Acc : 62.72%  \n",
            "val Loss 1.0476  Acc : 59.21%  \n",
            "epoch:  8\n",
            "train Loss 0.9297  Acc : 63.24%  \n",
            "val Loss 1.0606  Acc : 58.85%  \n",
            "epoch:  9\n",
            "train Loss 0.9294  Acc : 62.97%  \n",
            "val Loss 1.0732  Acc : 58.95%  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e2584e73-eace-4292-cff9-a9a0401054f9",
        "id": "SKesfmDS7dGH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!unzip \\X_test.h5.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  X_test.h5.zip\n",
            "  inflating: X_test.h5               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tzfktqUJ7cyD",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "import pandas as pd \n",
        "f= h5py.File('X_test.h5', 'r')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
