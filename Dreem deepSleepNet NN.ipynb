{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from models import * \n",
    "from Functions import * \n",
    "import h5py\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "#Working on GPU (Preferably)\n",
    "device =cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"this can be used to download the files from Kaggle to google colab for example \n",
    "    Kaggle API key needs to be uploaded  \"\"\"\n",
    "\n",
    "from google.colab import files\n",
    "upload=files.upload()\n",
    "!pip install -q kaggle\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!kaggle competitions download -c dreem-sleep-stages-2020 -p /content\n",
    "#We need to decompress the files\n",
    "!unzip \\X_train.h5.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  EEG Data Feature Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= h5py.File('X_train.h5', 'r')\n",
    "L=list(f.keys())\n",
    "y=pd.read_csv('y_train.csv')\n",
    "y=y['sleep_stage'].values\n",
    "df_eeg,n_measures_eeg,n_samples=Create_dataset(L[:7],f)\n",
    "F_s=50 #Sampling Frequency\n",
    "shape_eeg=(n_samples,n_measures_eeg,F_s*30)\n",
    "X_train,y_train,X_val,y_val=Oversample(df_eeg,y,shape_eeg,split=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "train_loader=create_loader(X_train,y_train,batch_size)\n",
    "val_loader=create_loader(X_val,y_val,batch_size)\n",
    "classifier_eeg = Feature_extractor(n_measures_eeg,F_s)\n",
    "classifier_eeg.to(device)\n",
    "optimizer = optim.Adam(classifier_eeg.parameters(),lr=0.1)#,weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler=lr_scheduler.StepLR(optimizer,step_size=10,gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "train Loss 2.2396  Acc : 36.64%  f1 score 0.36\n",
      "val Loss 1.5780  Acc : 41.86%  f1 score 0.37\n"
     ]
    }
   ],
   "source": [
    "#Training EEG data Feature EXtractor \n",
    "epochs=50\n",
    "Losses_v=[]\n",
    "Losses_t=[]\n",
    "for epoch in range(epochs):\n",
    "  print('epoch: ',epoch)\n",
    "  Losses_t+=Train_model(classifier_eeg,criterion,optimizer,train_loader,scheduler,device,mode='train')\n",
    "  Losses_v+=Train_model(classifier_eeg,criterion,optimizer,val_loader,scheduler,device,mode='val')\n",
    "#Saving State\n",
    "w_eeg=classifier_eeg.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accel+Pulsometer Data Feature Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pul=pd.read_csv('y_train.csv')\n",
    "y_pul=y_pul['sleep_stage'].values\n",
    "df_pul,n_measures_pul,n_samples=Create_dataset(L[-4:],f)\n",
    "F_s_pul=10 #Sampling Frequency\n",
    "shape_pul=(n_samples,n_measures_pul,F_s_pul*30)\n",
    "X_train_pul,y_train_pul,X_val_pul,y_val_pul=Oversample(df_pul,y_pul,shape_pul,split=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "train_loader_pul=create_loader(X_train_pul,y_train_pul,batch_size)\n",
    "val_loader_pul=create_loader(X_val_pul,y_val_pul,batch_size)\n",
    "classifier_pul = Feature_extractor(n_measures_pul,F_s_pul)\n",
    "classifier_pul.to(device)\n",
    "optimizer = optim.Adam(classifier_pul.parameters(),lr=0.1)#,weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler=lr_scheduler.StepLR(optimizer,step_size=10,gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "train Loss 2.2937  Acc : 36.06%  f1 score 0.36\n",
      "val Loss 1.3472  Acc : 35.74%  f1 score 0.34\n"
     ]
    }
   ],
   "source": [
    "#Training Acceloremeter+Pulsometer Feature EXtractor \n",
    "epochs=30\n",
    "Losses_v=[]\n",
    "Losses_t=[]\n",
    "for epoch in range(epochs):\n",
    "  print('epoch: ',epoch)\n",
    "  Losses_t+=Train_model(classifier_pul,criterion,optimizer,train_loader_pul,scheduler,device,mode='train')\n",
    "  Losses_v+=Train_model(classifier_pul,criterion,optimizer,val_loader_pul,scheduler,device,mode='val')\n",
    "#Saving State\n",
    "w_pul=classifier_pul.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Sequential   training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'------------------'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Sequential Datasets Here\n",
    "lookback=3\n",
    "dataX,dataY=Create_Sequential_data(df_eeg,lookback=lookback,n_measures=n_measures_eeg,labels=y)\n",
    "dataX_pul,dataY_pul=Create_Sequential_data(df_pul,lookback=lookback,n_measures=n_measures_pul,labels=y_pul)\n",
    "data=np.concatenate((dataX.reshape(dataX.shape[0:2]+(-1,)),dataX_pul.reshape(dataX_pul.shape[0:2]+(-1,))),axis=2)\n",
    "\"\"\"We can use this To free Up memory if needed\"\"\"\n",
    "#del dataX,dataX_pul\n",
    "\"\"\"------------------\"\"\"\n",
    "dataX_train,dataX_val,dataY_train,dataY_val=train_test_split(data,dataY,test_size=.3,stratify=dataY)\n",
    "Seq_train_loader=create_loader(dataX_train,dataY_train,batch_size=batch_size)\n",
    "Seq_val_loader=create_loader(dataX_val,dataY_val,batch_size=batch_size)\n",
    "\"\"\"Same We can use this To free Up memory if needed\"\"\"\n",
    "#del dataX_train,dataX_val,data\n",
    "\"\"\"------------------\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq=Seq_learn(classifier_eeg.n_features+classifier_pul.n_features,lookback=lookback,drop=0)\n",
    "seq.to(device)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we Freeze the feature Extractors wheights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_eeg.load_state_dict(w_eeg)\n",
    "classifier_pul.load_state_dict(w_pul)\n",
    "for param in classifier_eeg.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in classifier_pul.parameters():\n",
    "    param.requires_grad = False\n",
    "optimizer=optim.Adam([{'params':classifier_eeg.parameters(),'lr':0.001},\n",
    "            {'params':classifier_pul.parameters(),'lr':0.001},\n",
    "            {'params':seq.parameters()}],lr=0.1)#,weight_decay=1e-4)\n",
    "scheduler=lr_scheduler.StepLR(optimizer,step_size=10,gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "train Loss 4.2428  Acc : 49.63%  f1 score 0.49\n",
      "val Loss 1.1075  Acc : 60.25%  f1 score 0.60\n"
     ]
    }
   ],
   "source": [
    "epochs=1\n",
    "Losses_v=[]\n",
    "Losses_t=[]\n",
    "models=(classifier_eeg,classifier_pul,seq)\n",
    "for epoch in range(epochs):\n",
    "  print('epoch: ',epoch)\n",
    "  Losses_t+=Train_seq_model(models,criterion,optimizer,Seq_train_loader,scheduler,shape_eeg,shape_pul,device,lookback,mode='train')\n",
    "  Losses_v+=Train_seq_model(models,criterion,optimizer,Seq_val_loader,scheduler,shape_eeg,shape_pul,device,lookback,mode='val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning the feature Extractors wheights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in classifier_eeg.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in classifier_pul.parameters():\n",
    "    param.requires_grad = True\n",
    "optimizer=optim.Adam([{'params':classifier_eeg.parameters(),'lr':0.001},\n",
    "            {'params':classifier_pul.parameters(),'lr':0.001},\n",
    "            {'params':seq.parameters()}],lr=0.01)#,weight_decay=1e-4)\n",
    "scheduler=lr_scheduler.StepLR(optimizer,step_size=10,gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 462.00 MiB (GPU 0; 4.00 GiB total capacity; 2.54 GiB already allocated; 31.90 MiB free; 363.84 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-834b0df9ed08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch: '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m   \u001b[0mLosses_t\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mTrain_seq_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSeq_train_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshape_eeg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshape_pul\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlookback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m   \u001b[0mLosses_v\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mTrain_seq_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSeq_val_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshape_eeg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshape_pul\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlookback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\OMA cours\\ML\\Final_model\\Functions.py\u001b[0m in \u001b[0;36mTrain_seq_model\u001b[1;34m(models, criterion, optimizer, loader, scheduler, shape_eeg, shape_pul, device, lookback, mode)\u001b[0m\n\u001b[0;32m    215\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Finance\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \"\"\"\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Finance\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 462.00 MiB (GPU 0; 4.00 GiB total capacity; 2.54 GiB already allocated; 31.90 MiB free; 363.84 MiB cached)"
     ]
    }
   ],
   "source": [
    "epochs=30\n",
    "Losses_v=[]\n",
    "Losses_t=[]\n",
    "models=(classifier_eeg,classifier_pul,seq)\n",
    "for epoch in range(epochs):\n",
    "  print('epoch: ',epoch)\n",
    "  Losses_t+=Train_seq_model(models,criterion,optimizer,Seq_train_loader,scheduler,shape_eeg,shape_pul,device,lookback,mode='train')\n",
    "  Losses_v+=Train_seq_model(models,criterion,optimizer,Seq_val_loader,scheduler,shape_eeg,shape_pul,device,lookback,mode='val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerating Testing Files For Kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If files were downloaded without Unzipping Uncomment'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"If files were downloaded without Unzipping Uncomment\"\"\"\n",
    "#!unzip \\X_test.h5.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= h5py.File('X_test.h5', 'r')  \n",
    "Preds=Test_seq_model((classifier_eeg,classifier_pul,seq),batch_size,f ,L[:7],L[-4:],F_s,F_s_pul,lookback,w_eeg,w_pul,device )\n",
    "Preds.to_csv('submission.csv',index=True,header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
