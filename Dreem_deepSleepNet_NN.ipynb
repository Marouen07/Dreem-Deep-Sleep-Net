{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "YRM52GlhtnMB",
    "outputId": "fe59265d-4031-43d8-c927-85d4ec7852ff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from models import * \n",
    "from Functions import * \n",
    "import h5py\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "CyINbuxDtnME",
    "outputId": "3b82fc86-3719-49d6-e6fc-dfe8b791cbed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "#Working on GPU (Preferably)\n",
    "device =cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "_dRqz-XwtnMG",
    "outputId": "1b7a9de1-db1b-4529-fde0-a748a6bad197"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-e527e797-2ba6-45b2-bcea-228a3a3922f1\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-e527e797-2ba6-45b2-bcea-228a3a3922f1\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle.json\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
      "Downloading X_test.h5.zip to /content\n",
      " 99% 1.00G/1.01G [00:10<00:00, 99.2MB/s]\n",
      "100% 1.01G/1.01G [00:10<00:00, 103MB/s] \n",
      "Downloading X_train.h5.zip to /content\n",
      "100% 0.99G/1.00G [00:17<00:00, 71.3MB/s]\n",
      "100% 1.00G/1.00G [00:17<00:00, 62.6MB/s]\n",
      "Downloading sample_submission.csv to /content\n",
      "  0% 0.00/195k [00:00<?, ?B/s]\n",
      "100% 195k/195k [00:00<00:00, 199MB/s]\n",
      "Downloading y_train.csv to /content\n",
      "  0% 0.00/182k [00:00<?, ?B/s]\n",
      "100% 182k/182k [00:00<00:00, 179MB/s]\n",
      "Archive:  X_train.h5.zip\n",
      "  inflating: X_train.h5              \n"
     ]
    }
   ],
   "source": [
    "\"\"\"this can be used to download the files from Kaggle to google colab for example \n",
    "    Kaggle API key needs to be uploaded  \"\"\"\n",
    "\n",
    "from google.colab import files\n",
    "upload=files.upload()\n",
    "!pip install -q kaggle\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!kaggle competitions download -c dreem-sleep-stages-2020 -p /content\n",
    "#We need to decompress the files\n",
    "!unzip \\X_train.h5.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gjJVCKwNtnMI"
   },
   "source": [
    "#  EEG Data Feature Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LHc3cvmutnMI"
   },
   "outputs": [],
   "source": [
    "f= h5py.File('X_train.h5', 'r')\n",
    "L=list(f.keys())\n",
    "y=pd.read_csv('y_train.csv')\n",
    "y=y['sleep_stage'].values\n",
    "df_eeg,n_measures_eeg,n_samples=Create_dataset(L[:7],f)\n",
    "F_s=50 #Sampling Frequency\n",
    "shape_eeg=(n_samples,n_measures_eeg,F_s*30)\n",
    "X_train,y_train,X_val,y_val=Oversample(df_eeg,y,shape_eeg,split=.2,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EKuRZrpFtnMK"
   },
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "train_loader=create_loader(X_train,y_train,batch_size)\n",
    "val_loader=create_loader(X_val,y_val,batch_size)\n",
    "classifier_eeg = Feature_extractor(n_measures_eeg,F_s)\n",
    "classifier_eeg.to(device)\n",
    "optimizer = optim.Adam(classifier_eeg.parameters(),lr=0.1)#,weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler=lr_scheduler.StepLR(optimizer,step_size=10,gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "MNuQEs7GtnMM",
    "outputId": "181ff169-68ae-4c31-ed7e-5f34df3259f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "train Loss 0.6609  Acc : 75.11%  f1 score 0.75\n",
      "val Loss 0.8080  Acc : 69.95%  f1 score 0.70\n",
      "epoch:  1\n",
      "train Loss 0.6244  Acc : 76.20%  f1 score 0.76\n",
      "val Loss 0.7993  Acc : 70.21%  f1 score 0.71\n",
      "epoch:  2\n",
      "train Loss 0.6186  Acc : 76.61%  f1 score 0.77\n",
      "val Loss 0.8013  Acc : 70.05%  f1 score 0.70\n",
      "epoch:  3\n",
      "train Loss 0.6185  Acc : 76.56%  f1 score 0.77\n",
      "val Loss 0.8027  Acc : 69.89%  f1 score 0.70\n",
      "epoch:  4\n",
      "train Loss 0.6201  Acc : 76.55%  f1 score 0.77\n",
      "val Loss 1.0115  Acc : 70.23%  f1 score 0.71\n"
     ]
    }
   ],
   "source": [
    "#Training EEG data Feature EXtractor \n",
    "epochs=50\n",
    "Losses_v=[]\n",
    "Losses_t=[]\n",
    "for epoch in range(epochs):\n",
    "  print('epoch: ',epoch)\n",
    "  Losses_t+=Train_model(classifier_eeg,criterion,optimizer,train_loader,scheduler,device,mode='train')\n",
    "  Losses_v+=Train_model(classifier_eeg,criterion,optimizer,val_loader,scheduler,device,mode='val')\n",
    "#Saving State\n",
    "w_eeg=classifier_eeg.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tdmyj6KotnMO"
   },
   "source": [
    "# Accel+Pulsometer Data Feature Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ay0d-TbwtnMO"
   },
   "outputs": [],
   "source": [
    "y_pul=pd.read_csv('y_train.csv')\n",
    "y_pul=y_pul['sleep_stage'].values\n",
    "df_pul,n_measures_pul,n_samples=Create_dataset(L[-4:],f)\n",
    "F_s_pul=10 #Sampling Frequency\n",
    "shape_pul=(n_samples,n_measures_pul,F_s_pul*30)\n",
    "X_train_pul,y_train_pul,X_val_pul,y_val_pul=Oversample(df_pul,y_pul,shape_pul,split=.2,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jDLQ9-BRtnMQ"
   },
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "train_loader_pul=create_loader(X_train_pul,y_train_pul,batch_size)\n",
    "val_loader_pul=create_loader(X_val_pul,y_val_pul,batch_size)\n",
    "classifier_pul = Feature_extractor(n_measures_pul,F_s_pul)\n",
    "classifier_pul.to(device)\n",
    "optimizer = optim.Adam(classifier_pul.parameters(),lr=0.1)#,weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler=lr_scheduler.StepLR(optimizer,step_size=10,gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "sB3qH-tQtnMS",
    "outputId": "23eceafd-425b-475b-a0eb-7a80ed3aba1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "train Loss 1.0660  Acc : 58.95%  f1 score 0.59\n",
      "val Loss 1.1392  Acc : 54.09%  f1 score 0.54\n",
      "epoch:  1\n",
      "train Loss 1.0601  Acc : 59.36%  f1 score 0.59\n",
      "val Loss 1.1430  Acc : 54.19%  f1 score 0.54\n",
      "epoch:  2\n",
      "train Loss 1.0574  Acc : 59.08%  f1 score 0.59\n",
      "val Loss 1.1514  Acc : 53.50%  f1 score 0.54\n",
      "epoch:  3\n",
      "train Loss 1.0607  Acc : 59.33%  f1 score 0.59\n",
      "val Loss 1.1403  Acc : 53.16%  f1 score 0.53\n",
      "epoch:  4\n",
      "train Loss 1.0525  Acc : 59.24%  f1 score 0.59\n",
      "val Loss 1.1254  Acc : 54.96%  f1 score 0.55\n"
     ]
    }
   ],
   "source": [
    "#Training Acceloremeter+Pulsometer Feature EXtractor \n",
    "epochs=5\n",
    "Losses_v=[]\n",
    "Losses_t=[]\n",
    "for epoch in range(epochs):\n",
    "  print('epoch: ',epoch)\n",
    "  Losses_t+=Train_model(classifier_pul,criterion,optimizer,train_loader_pul,scheduler,device,mode='train')\n",
    "  Losses_v+=Train_model(classifier_pul,criterion,optimizer,val_loader_pul,scheduler,device,mode='val')\n",
    "#Saving State\n",
    "w_pul=classifier_pul.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Riq4ddutnMT"
   },
   "source": [
    "# LSTM Sequential   training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "t8ilB95LtnMU",
    "outputId": "3f32b303-6b9c-475e-8ea5-0282605efa78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'------------------'"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Sequential Datasets Here\n",
    "lookback=3\n",
    "dataX,dataY=Create_Sequential_data(df_eeg,lookback=lookback,n_measures=n_measures_eeg,labels=y)\n",
    "dataX_pul,dataY_pul=Create_Sequential_data(df_pul,lookback=lookback,n_measures=n_measures_pul,labels=y_pul)\n",
    "data=np.concatenate((dataX.reshape(dataX.shape[0:2]+(-1,)),dataX_pul.reshape(dataX_pul.shape[0:2]+(-1,))),axis=2)\n",
    "\"\"\"We can use this To free Up memory if needed\"\"\"\n",
    "del dataX,dataX_pul\n",
    "\"\"\"------------------\"\"\"\n",
    "dataX_train,dataX_val,dataY_train,dataY_val=train_test_split(data,dataY,test_size=.2,shuffle=False)\n",
    "Seq_train_loader=create_loader(dataX_train,dataY_train,batch_size=batch_size)\n",
    "Seq_val_loader=create_loader(dataX_val,dataY_val,batch_size=batch_size)\n",
    "\"\"\"Same We can use this To free Up memory if needed\"\"\"\n",
    "del dataX_train,dataX_val,data\n",
    "\"\"\"------------------\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h6EBBs_dtnMW"
   },
   "outputs": [],
   "source": [
    "seq=Seq_learn(classifier_eeg.n_features+classifier_pul.n_features,lookback=lookback,drop=0)\n",
    "seq.to(device)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2gigv3iNtnMX"
   },
   "source": [
    "### First we Freeze the feature Extractors wheights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PVutvDmPtnMY"
   },
   "outputs": [],
   "source": [
    "classifier_eeg.load_state_dict(w_eeg)\n",
    "classifier_pul.load_state_dict(w_pul)\n",
    "for param in classifier_eeg.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in classifier_pul.parameters():\n",
    "    param.requires_grad = False\n",
    "optimizer=optim.Adam([{'params':classifier_eeg.parameters(),'lr':0.001},\n",
    "            {'params':classifier_pul.parameters(),'lr':0.001},\n",
    "            {'params':seq.parameters()}],lr=0.1)#,weight_decay=1e-4)\n",
    "scheduler=lr_scheduler.StepLR(optimizer,step_size=10,gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "colab_type": "code",
    "id": "l7er_ykHtnMa",
    "outputId": "46c7739f-a5ca-4c99-c2bf-90ccd24459cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "train Loss 0.8941  Acc : 78.97%  f1 score 0.79\n",
      "val Loss 0.7523  Acc : 82.09%  f1 score 0.82\n",
      "epoch:  1\n",
      "train Loss 0.8922  Acc : 78.87%  f1 score 0.79\n",
      "val Loss 0.8386  Acc : 82.35%  f1 score 0.82\n",
      "epoch:  2\n",
      "train Loss 0.9128  Acc : 79.09%  f1 score 0.79\n",
      "val Loss 185.5197  Acc : 82.23%  f1 score 0.82\n",
      "epoch:  3\n",
      "train Loss 0.9282  Acc : 78.48%  f1 score 0.78\n",
      "val Loss 3.7416  Acc : 82.26%  f1 score 0.82\n",
      "epoch:  4\n",
      "train Loss 0.8739  Acc : 79.41%  f1 score 0.79\n",
      "val Loss 1.9615  Acc : 82.57%  f1 score 0.83\n",
      "epoch:  5\n",
      "train Loss 0.9085  Acc : 78.72%  f1 score 0.79\n",
      "val Loss 0.7314  Acc : 82.50%  f1 score 0.83\n",
      "epoch:  6\n",
      "train Loss 0.9117  Acc : 78.92%  f1 score 0.79\n",
      "val Loss 0.7362  Acc : 82.51%  f1 score 0.83\n",
      "epoch:  7\n",
      "train Loss 0.9109  Acc : 78.33%  f1 score 0.78\n",
      "val Loss 0.7435  Acc : 82.20%  f1 score 0.82\n",
      "epoch:  8\n",
      "train Loss 0.8947  Acc : 79.30%  f1 score 0.79\n",
      "val Loss 0.7454  Acc : 82.23%  f1 score 0.82\n",
      "epoch:  9\n",
      "train Loss 0.8973  Acc : 78.79%  f1 score 0.79\n",
      "val Loss 0.7373  Acc : 82.34%  f1 score 0.82\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "Losses_v=[]\n",
    "Losses_t=[]\n",
    "models=(classifier_eeg,classifier_pul,seq)\n",
    "for epoch in range(epochs):\n",
    "  print('epoch: ',epoch)\n",
    "  Losses_t+=Train_seq_model(models,criterion,optimizer,Seq_train_loader,scheduler,shape_eeg,shape_pul,device,lookback,mode='train')\n",
    "  Losses_v+=Train_seq_model(models,criterion,optimizer,Seq_val_loader,scheduler,shape_eeg,shape_pul,device,lookback,mode='val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GCpMRri4tnMc"
   },
   "source": [
    "### Fine Tuning parameters along with the feature Extractors wheights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GlYf8t04tnMd"
   },
   "outputs": [],
   "source": [
    "classifier_eeg.load_state_dict(w_eeg)\n",
    "classifier_pul.load_state_dict(w_pul)\n",
    "for param in classifier_eeg.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in classifier_pul.parameters():\n",
    "    param.requires_grad = True\n",
    "optimizer=optim.Adam([{'params':classifier_eeg.parameters(),'lr':0.001},\n",
    "            {'params':classifier_pul.parameters(),'lr':0.001},\n",
    "            {'params':seq.parameters()}],lr=0.005)#,weight_decay=1e-4)\n",
    "scheduler=lr_scheduler.StepLR(optimizer,step_size=10,gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "4QTIk_U6tnMe",
    "outputId": "75c55f7b-40bd-4ced-dd8d-dbce0d2d7d98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "train Loss 0.5000  Acc : 81.68%  f1 score 0.81\n",
      "val Loss 0.4619  Acc : 83.36%  f1 score 0.83\n",
      "epoch:  1\n",
      "train Loss 0.5008  Acc : 81.36%  f1 score 0.81\n",
      "val Loss 0.4597  Acc : 83.49%  f1 score 0.84\n",
      "epoch:  2\n",
      "train Loss 0.4987  Acc : 81.40%  f1 score 0.81\n",
      "val Loss 6.9405  Acc : 83.28%  f1 score 0.83\n",
      "epoch:  3\n",
      "train Loss 0.5010  Acc : 81.15%  f1 score 0.81\n",
      "val Loss 1.1146  Acc : 83.39%  f1 score 0.83\n",
      "epoch:  4\n",
      "train Loss 0.5029  Acc : 81.49%  f1 score 0.81\n",
      "val Loss 7.1424  Acc : 83.50%  f1 score 0.84\n",
      "epoch:  5\n",
      "train Loss 0.4924  Acc : 81.68%  f1 score 0.82\n",
      "val Loss 2.0651  Acc : 83.39%  f1 score 0.83\n",
      "epoch:  6\n",
      "train Loss 0.4955  Acc : 81.69%  f1 score 0.82\n",
      "val Loss 1.7013  Acc : 83.76%  f1 score 0.84\n",
      "epoch:  7\n",
      "train Loss 0.4902  Acc : 81.72%  f1 score 0.82\n",
      "val Loss 0.6659  Acc : 83.38%  f1 score 0.83\n",
      "epoch:  8\n",
      "train Loss 0.4958  Acc : 81.85%  f1 score 0.82\n",
      "val Loss 0.4598  Acc : 83.50%  f1 score 0.84\n",
      "epoch:  9\n",
      "train Loss 0.5085  Acc : 81.34%  f1 score 0.81\n",
      "val Loss 0.6868  Acc : 83.19%  f1 score 0.83\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "Losses_v=[]\n",
    "Losses_t=[]\n",
    "models=(classifier_eeg,classifier_pul,seq)\n",
    "for epoch in range(epochs):\n",
    "  print('epoch: ',epoch)\n",
    "  Losses_t+=Train_seq_model(models,criterion,optimizer,Seq_train_loader,scheduler,shape_eeg,shape_pul,device,lookback,mode='train')\n",
    "  Losses_v+=Train_seq_model(models,criterion,optimizer,Seq_val_loader,scheduler,shape_eeg,shape_pul,device,lookback,mode='val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vzitW_rOtnMg"
   },
   "source": [
    "### Generating Testing Files For Kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jKc2B0qHtnMh",
    "outputId": "95df5ec4-aae8-46ea-b2a8-901a14ae331c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If files were downloaded without Unzipping Uncomment'"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"If files were downloaded without Unzipping Uncomment\"\"\"\n",
    "#!unzip \\X_test.h5.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WjIvW4MntnMi"
   },
   "outputs": [],
   "source": [
    "f= h5py.File('X_test.h5', 'r')  \n",
    "Preds=Test_seq_model((classifier_eeg,classifier_pul,seq),batch_size,f ,L[:7],L[-4:],F_s,F_s_pul,lookback,w_eeg,w_pul,device )\n",
    "Preds.to_csv('submission.csv',index=True,header=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Dreem deepSleepNet NN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
